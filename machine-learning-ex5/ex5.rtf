{\rtf1\ansi\deff3\adeflang1025
{\fonttbl{\f0\froman\fprq2\fcharset0 Times New Roman;}{\f1\froman\fprq2\fcharset2 Symbol;}{\f2\fswiss\fprq2\fcharset0 Arial;}{\f3\froman\fprq2\fcharset0 Liberation Serif{\*\falt Times New Roman};}{\f4\fswiss\fprq2\fcharset0 Liberation Sans{\*\falt Arial};}{\f5\froman\fprq2\fcharset0 Georgia;}{\f6\froman\fprq2\fcharset129 \'b8\'bc\'c0\'ba \'b0\'ed\'b5\'f1;}{\f7\fnil\fprq2\fcharset0 Noto Sans CJK SC Regular;}{\f8\fnil\fprq2\fcharset0 FreeSans;}{\f9\fswiss\fprq0\fcharset128 FreeSans;}}
{\colortbl;\red0\green0\blue0;\red0\green0\blue255;\red0\green255\blue255;\red0\green255\blue0;\red255\green0\blue255;\red255\green0\blue0;\red255\green255\blue0;\red255\green255\blue255;\red0\green0\blue128;\red0\green128\blue128;\red0\green128\blue0;\red128\green0\blue128;\red128\green0\blue0;\red128\green128\blue0;\red128\green128\blue128;\red192\green192\blue192;}
{\stylesheet{\s0\snext0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033 Normal;}
{\s15\sbasedon0\snext16\sb240\sa120\keepn\dbch\af7\dbch\af8\afs28\loch\f4\fs28 Heading;}
{\s16\sbasedon0\snext16\sl288\slmult1\sb0\sa140 Text Body;}
{\s17\sbasedon16\snext17\sl288\slmult1\sb0\sa140\dbch\af9 List;}
{\s18\sbasedon0\snext18\sb120\sa120\noline\i\dbch\af9\afs24\ai\fs24 Caption;}
{\s19\sbasedon0\snext19\noline\dbch\af9 Index;}
}{\*\generator LibreOffice/5.1.6.2$Linux_X86_64 LibreOffice_project/10m0$Build-2}{\info{\creatim\yr0\mo0\dy0\hr0\min0}{\revtim\yr2017\mo11\dy8\hr17\min33}{\printim\yr0\mo0\dy0\hr0\min0}}\deftab720
\viewscale180
{\*\pgdsctbl
{\pgdsc0\pgdscuse451\pgwsxn12240\pghsxn15840\marglsxn1800\margrsxn1800\margtsxn1440\margbsxn1440\pgdscnxt0 Default Style;}}
\formshade{\*\pgdscno0}\paperh15840\paperw12240\margl1800\margr1800\margt1440\margb1440\sectd\sbknone\sectunlocked1\pgndec\pgwsxn12240\pghsxn15840\marglsxn1800\margrsxn1800\margtsxn1440\margbsxn1440\ftnbj\ftnstart1\ftnrstcont\ftnnar\aenddoc\aftnrstcont\aftnstart1\aftnnrlc
{\*\ftnsep}\pgndec\pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b\rtlch \ltrch\loch\fs32\lang1033\loch\f5
List of Files for this assignment:}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
ex5.m - Octave/MATLAB script that steps you through the exercise}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
ex5data1.mat - Dataset}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
submit.m - Submission script that sends your solutions to our servers}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
featureNormalize.m - Feature normalization function}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
fmincg.m - Function minimization routine (similar to fminunc)}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
plotFit.m - Plot a polynomial fit}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
trainLinearReg.m - Trains linear regression using your cost function}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
[?] linearRegCostFunction.m - Regularized linear regression cost function}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
[?] learningCurve.m - Generates a learning curve}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
[?] polyFeatures.m - Maps data into polynomial feature space}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
[?] validationCurve.m - Generates a validation curve}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5

\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
In this }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
exercise}{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
, you will use the linear regression cost function and compute J_train and J_cv. Plus, you will plot J_train and J_cv as a function of training dataset size. Finally, you will plot J_train and J_cv as a function of lambda, the regularization parameter.}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5

\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
You may reuse your successfully implemented linear regression cost function w/regularization from the previous exercises. You should write down your implementation in linearRegCostFunction.m.}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5

\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
You will then implement code to generate learning curves. Recall that a learning curve plots training and cross validation error as a function of training set size. Your job is to fill in learningCurve.m so that it returns a vector of cost function values for the training set and cross validation set. The i-th element in the vector should be the value of cost function computed upon a training set with i instance(s) of data.}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5

\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
Notice that, with our linear model}{\cf1\b0\rtlch \ltrch\loch\fs24\lang1042\loch\f5
, }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
it }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1042\loch\f5
is }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
too simple for the data}{\cf1\b0\rtlch \ltrch\loch\fs24\lang1042\loch\f5
 }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
and resulted in under}{\cf1\b0\rtlch \ltrch\loch\fs24\lang1042\loch\f5
fi}{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
tting (high bias). You will}{\cf1\b0\rtlch \ltrch\loch\fs24\lang1042\loch\f5
 solve}{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
 this problem by adding more features. Given a vector X, your job is to implement polyFeatures.m such that it returns a matrix X_poly where the p-th column of X contains the values of X to the p-th power.}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5

\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
You will then implement code to generate the validation curves. Recall that a validation curve plots training and cross validation error as a function of regularization parameter. Your job is to fill in validationCurve.m so that it returns a vector of cost function values for the training set and cross validation set. The i-th element in the vector should be the value of cost function computed when lambda equals the given value in lambda_vec.}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af7\langfe2052\dbch\af8\afs24\alang1081\loch\f3\fs24\lang1033\sl276\slmult1\sb0\sa200\rtlch \ltrch\loch

\par }