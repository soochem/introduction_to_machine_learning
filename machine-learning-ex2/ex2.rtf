{\rtf1\ansi\deff3\adeflang1025
{\fonttbl{\f0\froman\fprq2\fcharset0 Times New Roman;}{\f1\froman\fprq2\fcharset2 Symbol;}{\f2\fswiss\fprq2\fcharset0 Arial;}{\f3\froman\fprq2\fcharset0 Liberation Serif{\*\falt Times New Roman};}{\f4\fswiss\fprq2\fcharset0 Liberation Sans{\*\falt Arial};}{\f5\froman\fprq2\fcharset0 Georgia;}{\f6\fnil\fprq2\fcharset0 Noto Sans CJK SC Regular;}{\f7\fnil\fprq2\fcharset0 FreeSans;}{\f8\fswiss\fprq0\fcharset128 FreeSans;}}
{\colortbl;\red0\green0\blue0;\red0\green0\blue255;\red0\green255\blue255;\red0\green255\blue0;\red255\green0\blue255;\red255\green0\blue0;\red255\green255\blue0;\red255\green255\blue255;\red0\green0\blue128;\red0\green128\blue128;\red0\green128\blue0;\red128\green0\blue128;\red128\green0\blue0;\red128\green128\blue0;\red128\green128\blue128;\red192\green192\blue192;\red161\green32\blue241;\red34\green140\blue34;\red255\green51\blue255;\red153\green0\blue255;}
{\stylesheet{\s0\snext0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033 Normal;}
{\s15\sbasedon0\snext16\sb240\sa120\keepn\dbch\af6\dbch\af7\afs28\loch\f4\fs28 Heading;}
{\s16\sbasedon0\snext16\sl288\slmult1\sb0\sa140 Text Body;}
{\s17\sbasedon16\snext17\sl288\slmult1\sb0\sa140\dbch\af8 List;}
{\s18\sbasedon0\snext18\sb120\sa120\noline\i\dbch\af8\afs24\ai\fs24 Caption;}
{\s19\sbasedon0\snext19\noline\dbch\af8 Index;}
}{\*\generator LibreOffice/5.1.6.2$Linux_X86_64 LibreOffice_project/10m0$Build-2}{\info{\creatim\yr0\mo0\dy0\hr0\min0}{\revtim\yr2017\mo9\dy22\hr11\min13}{\printim\yr0\mo0\dy0\hr0\min0}}\deftab720
\viewscale200
{\*\pgdsctbl
{\pgdsc0\pgdscuse451\pgwsxn12240\pghsxn15840\marglsxn1800\margrsxn1800\margtsxn1440\margbsxn1440\pgdscnxt0 Default Style;}}
\formshade{\*\pgdscno0}\paperh15840\paperw12240\margl1800\margr1800\margt1440\margb1440\sectd\sbknone\sectunlocked1\pgndec\pgwsxn12240\pghsxn15840\marglsxn1800\margrsxn1800\margtsxn1440\margbsxn1440\ftnbj\ftnstart1\ftnrstcont\ftnnar\aenddoc\aftnrstcont\aftnstart1\aftnnrlc
{\*\ftnsep}\pgndec\pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b\rtlch \ltrch\loch\fs32\lang1033\loch\f5
List of Files for this assignment:}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
ex2.m - Octave/MATLAB script that steps you through the exercise}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
ex2 reg.m - Octave/MATLAB script for the later parts of the exercise}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
ex2data1.txt - Training set for the first half of the exercise}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
ex2data2.txt - Training set for the second half of the exercise}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
mapFeature.m - Function to generate polynomial features}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
plotDecisionBoundary.m - Function to plot classifier's decision boundary}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
fmincg.m -  Function to optimize parameters of cost function.}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
[?] sigmoid.m - Sigmoid Function}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
[?] costFunction.m - Logistic Regression Cost Function}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
[?] predict.m - Logistic Regression Prediction Function}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
[?] costFunctionReg.m - Regularized Logistic Regression Cost}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5

\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs40\lang1033\loch\f5
Section 1: }{\cf1\b0\rtlch \ltrch\loch\fs40\lang1033\loch\f5
Logistic}{\cf1\b0\rtlch \ltrch\loch\fs40\lang1033\loch\f5
 regression }{\cf1\b0\rtlch \ltrch\loch\fs40\lang1033\loch\f5
without Regularization}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033\cf1\b0\rtlch \ltrch\loch\fs29\lang1033\loch\f5

\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
In this part, you will implement }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
some code for performing training with logistic regression without using regularization.}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033\cf1\b0\rtlch \ltrch\loch\fs29\lang1033\loch\f5

\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs32\lang1033\loch\f5
Part 1: Plotting the Data}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
The loading of training data (assigned to variables X and y in the code) has already been done for you as follows:}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5

\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\afs20\rtlch \ltrch\loch\fs20\lang1033\loch\f5
data = load(}{\cf20\b0\afs20\rtlch \ltrch\loch\fs20\lang1033\loch\f5
'ex2data1.txt'}{\cf1\b0\afs20\rtlch \ltrch\loch\fs20\lang1033\loch\f5
);}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\afs20\rtlch \ltrch\loch\fs20\lang1033\loch\f5
X = data(:, [1, 2]); y = data(:, 3);}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5

\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
Training data can be visualized within the rectangular 2D plot space. The code to do this has also been written down for you.}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5

\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5

\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs32\lang1033\loch\f5
Part 2: Computing }{\cf1\b0\rtlch \ltrch\loch\fs32\lang1033\loch\f5
Initial Cost and Gradient}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
the backbone code for}{\cf1\b0\afs24\rtlch \ltrch\loch\fs24\lang1033\loch\f5
 }{\cf1\b0\afs24\rtlch \ltrch\loch\fs24\lang1033\loch\f5
c}{\cf1\b0\afs24\rtlch \ltrch\loch\fs24\lang1033\loch\f5
omputing }{\cf1\b0\afs24\rtlch \ltrch\loch\fs24\lang1033\loch\f5
initial cost and gradient}{\cf1\b0\afs24\rtlch \ltrch\loch\fs24\lang1033\loch\f5
 is already written down for you. }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
For this part, }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
all you need to do is to }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
implement costFunction().}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033\rtlch \ltrch\loch

\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033\sl240\slmult1\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5

\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs32\lang1033\loch\f5
Part 3: Optimizing using fminunc}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
In this part, you will use a built-in function (fminunc) to find the optimal parameters theta. fminunc }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
s}{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
peeds up }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
optimizing}{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
 theta parameters }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
of }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
your function to compute cost. }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
It }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
can be thought of as a}{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
n alternative to gradientDescent() function. }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
After optimization, theta parameters will be used for visualizing the decision boundary on the training data.}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
Although there is nothing needed to do for this section, please note that some machines do not support fminunc. This is because fminunc is a closed-source function; you can use it only if MATLAB (and not Octave) is used along with proper license. To deal with this problem, there is another function named fmincg() that performs function optimization in a similar fashion. This function is open-source and is already included in the source directory for you. Utilizing the try-catch block, if your machine cannot execute fminunc, it will automatically execute the fmincg() function.}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\fs24\lang1033\loch\f5
 }
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5

\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs32\lang1033\loch\f5
Part 4: }{\cf1\b0\rtlch \ltrch\loch\fs32\lang1033\loch\f5
Prediction and Evaluation}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
Now that you have }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
finished training, you would check the prediction on a given test data. Then, you would compute the accuracy of training on our training set. The backbone code for doing this has been already written for you in ex2.m. Your job is to implement sigmoid() function and predict() function.}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5

\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs40\lang1033\loch\f5
Section 2: }{\cf1\b0\rtlch \ltrch\loch\fs40\lang1033\loch\f5
Logistic}{\cf1\b0\rtlch \ltrch\loch\fs40\lang1033\loch\f5
 regression }{\cf1\b0\rtlch \ltrch\loch\fs40\lang1033\loch\f5
with Regularization}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033\cf1\b0\rtlch \ltrch\loch\fs34\lang1033\loch\f5

\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
In this part, you will implement }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
some code for performing training with logistic regression WITH using regularization. }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
The base code for this is specified in ex2_reg.m.}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5

\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs32\lang1033\loch\f5
Part 5: }{\cf1\b0\rtlch \ltrch\loch\fs32\lang1033\loch\f5
Adding Polynomial Features and }{\cf1\b0\rtlch \ltrch\loch\fs32\lang1033\loch\f5
Computing }{\cf1\b0\rtlch \ltrch\loch\fs32\lang1033\loch\f5
Initial Cost and Gradient}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
In this part, you are given a dataset with data points that are not linearly separable. However, logistic regression can still be used for classifying the data points. This is possible by adding polynomial features. The code to do this is already done for you.}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
After that, you compute the initial cost and gradient for regularized logistic regression. T}{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
he backbone code }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
to do this }{\cf1\b0\afs24\rtlch \ltrch\loch\fs24\lang1033\loch\f5
is already written down for you. }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
For this part, }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
all you need to do is to }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
implement costFunction}{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
Reg}{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
(), }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
which takes in extra argument \u8211\'96 the regularization parameter lambda}{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
.}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5

\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs32\lang1033\loch\f5
Part 6: Optimizing using fminunc }{\cf1\b0\rtlch \ltrch\loch\fs32\lang1033\loch\f5
+ }{\cf1\b0\rtlch \ltrch\loch\fs32\lang1033\loch\f5
Prediction and Evaluation}
\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5

\par \pard\plain \s0\nowidctlpar\hyphpar0\cf0\kerning1\dbch\af6\langfe2052\dbch\af7\afs24\alang1081\loch\f3\fs24\lang1033{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
In this part, you will use a built-in function (fminunc) to find the optimal parameters theta. }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
As mentioned before, fminunc() needs a license, so if it fails, fmincg() will be used instead. }{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
Then, you would compute the accuracy of training on our training set. The backbone code for doing this has been already written for you in ex2_}{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
reg}{\cf1\b0\rtlch \ltrch\loch\fs24\lang1033\loch\f5
.m. Your job is to implement predict() function.}
\par }